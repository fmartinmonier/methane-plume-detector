{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methane Plume Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightning.pytorch as pl \n",
    "import wandb\n",
    "import ee\n",
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from src.models.methane_unet import UNetMethane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_date = \"2022-10-28\"\n",
    "obs_lat = 32.28470055\n",
    "obs_lon = -108.284939\n",
    "query_dict = {\n",
    "    obs_date: (obs_lat, obs_lon)\n",
    "}\n",
    "\n",
    "# Define the window size of the queried scene in meters. Window will be a square of size 2*buffer_distance x 2*buffer_distance\n",
    "buffer_distance = 2000\n",
    "# Define the cloud threshold for the queried scene (in %)\n",
    "cloud_threshold = 0\n",
    "# Define satellite\n",
    "satellite = \"S2\"\n",
    "\n",
    "# Define model used\n",
    "# Import an object from a s3 bucket called methane-detector, the s3 bucket is located in the same account as this repo. The object name is unet_64_standardized.ckpt\n",
    "\n",
    "\n",
    "model_name = \"unet_64_standardized.ckpt\"\n",
    "base_filters = 64 # This should be a power of two and can be found in the name of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query EO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate to the GEE API\n",
    "ee.Authenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tools.gee import query_ee_band_data\n",
    "ee.Initialize()\n",
    "\n",
    "raw_scene_list = []\n",
    "source_rates = []\n",
    "for date, coords in query_dict.items():\n",
    "    lat = coords[0]\n",
    "    lon = coords[1]\n",
    "    try:\n",
    "        source_rates.append(coords[2])\n",
    "    except:\n",
    "        source_rates.append(0)\n",
    "    \n",
    "    raw_scene, scene_date, successful_obs = query_ee_band_data(\n",
    "        lat,\n",
    "        lon,\n",
    "        lat_shift=0,\n",
    "        lon_shift=0,\n",
    "        buffer_distance=buffer_distance,\n",
    "        start_date=date,\n",
    "        n_days=1,\n",
    "        satellite_name=satellite,\n",
    "        cloud_threshold=cloud_threshold,\n",
    "        get_no2_bands=True,\n",
    "        get_ch4_bands=True,\n",
    "        get_aux_bands=True,\n",
    "        verbose=True,\n",
    "        cache=None,\n",
    "    )\n",
    "\n",
    "    raw_scene_list.append(raw_scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing function\n",
    "from src.tools.image import antialiasing_filter, change_resolution\n",
    "\n",
    "def preprocess_scene(scene):\n",
    "    channels = [\n",
    "        \"B2\",\n",
    "        \"B3\",\n",
    "        \"B4\",\n",
    "        \"B8\",\n",
    "        \"B11\",\n",
    "        \"B12\",\n",
    "    ]\n",
    "    for c in channels:\n",
    "        scene[c] = change_resolution(scene[c], target_resolution=scene[\"B2\"].shape)\n",
    "        scene[c] = np.where(scene[c] == 0, np.nan, scene[c])\n",
    "    scene = antialiasing_filter(scene, channels, sigma=0.5)\n",
    "        \n",
    "    return scene\n",
    "\n",
    "def compute_ndi(scene):\n",
    "    ndmi = (scene[\"B11\"] - scene[\"B12\"]) / (scene[\"B11\"] + scene[\"B12\"])\n",
    "    ndbi = (scene[\"B11\"] - scene[\"B8\"]) / (scene[\"B11\"] + scene[\"B8\"])\n",
    "    ndvi = (scene[\"B8\"] - scene[\"B4\"]) / (scene[\"B8\"] + scene[\"B4\"])\n",
    "    bsi = ((scene[\"B11\"] + scene[\"B4\"]) - (scene[\"B8\"] + scene[\"B2\"])) / ((scene[\"B11\"] + scene[\"B4\"]) + (scene[\"B8\"] + scene[\"B2\"]))\n",
    "\n",
    "    scene[\"ndmi\"] = ndmi\n",
    "    scene[\"ndbi\"] = ndbi\n",
    "    scene[\"ndvi\"] = ndvi\n",
    "    scene[\"bsi\"] = bsi\n",
    "    \n",
    "    return scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tools.image import standardize\n",
    "\n",
    "trusted_scene_list = []\n",
    "refined_scene_list = []\n",
    "\n",
    "for raw_data in raw_scene_list:\n",
    "    trusted_scene = preprocess_scene(raw_scene)\n",
    "    trusted_scene_ndi = compute_ndi(trusted_scene)\n",
    "\n",
    "    trusted_scene_list.append(trusted_scene_ndi)\n",
    "    refined_scene = standardize(trusted_scene_ndi)\n",
    "    refined_scene_list.append(refined_scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display one of the queried scene's SWIR12 and NDMI bands\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scene = refined_scene_list[0]\n",
    "\n",
    "f = plt.figure(figsize=(8, 4))\n",
    "\n",
    "subplot1 = f.add_subplot(1, 2, 1)\n",
    "im1 = subplot1.imshow(scene[\"B12\"], cmap=\"Greys_r\")\n",
    "subplot1.set_title(f\"SWIR 12 - {scene_date}\")\n",
    "\n",
    "subplot2 = f.add_subplot(1, 3, 1)\n",
    "im2 = subplot1.imshow(scene[\"ndmi\"], cmap=\"viridis\")\n",
    "subplot2.set_title(f\"NDMI - {scene_date}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build dataset for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import TestDataset, collate_fn\n",
    "\n",
    "test_dataset = TestDataset(refined_scene_list)\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1, \n",
    "    num_workers=1,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "model_path = f\"models/{model_name}\"\n",
    "s3 = boto3.resource('s3')\n",
    "checkpoint = s3.Bucket('methane-detector').download_file('unet_64_standardized.ckpt', 'unet_64_standardized.ckpt')\n",
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import CH4UNet\n",
    "\n",
    "# Define model backbone\n",
    "model = CH4UNet(in_channels=10, n_classes=1, base_filters=base_filters)\n",
    "\n",
    "# Populate model with weights\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "# Move model to gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, batch in enumerate(test_dataloader):\n",
    "    inputs = batch[\"image\"].to(device)\n",
    "    pixel_mask = batch[\"pixel_mask\"].to(device)\n",
    "    scene_date = batch[\"scene_date\"][0]\n",
    "    proba, mask = model(inputs)\n",
    "    inputs = inputs * pixel_mask\n",
    "    proba = proba * pixel_mask\n",
    "    mask = mask * pixel_mask\n",
    "\n",
    "    pred_mask = mask[0, :, :].squeeze().detach().cpu().numpy().astype(np.uint8)\n",
    "    prediction = proba[0, :, :].squeeze().detach().cpu().numpy()\n",
    "    image = inputs[0, 0, :, :].detach().cpu().numpy() # this should show the ndmi channel\n",
    "    \n",
    "    f = plt.figure(figsize=(15, 4))\n",
    "\n",
    "    subplot1 = f.add_subplot(1, 3, 1)\n",
    "    im1 = subplot1.imshow(image)\n",
    "    subplot1.set_title(f\"NDMI - {scene_date}\")\n",
    "    f.colorbar(im1, ax=subplot1)\n",
    "    \n",
    "\n",
    "    subplot3 = f.add_subplot(1, 3, 2)\n",
    "    im3 = subplot3.imshow(pred_mask, cmap=\"binary\")\n",
    "    subplot3.set_title(f\"Predicted Mask - {source_rates[batch_idx]} t/h\")\n",
    "    f.colorbar(im3, ax=subplot3)\n",
    "\n",
    "    subplot4 = f.add_subplot(1, 3, 3)\n",
    "    im4 = subplot4.imshow(prediction, cmap=\"plasma\")\n",
    "    subplot4.set_title(\"Probabilities\")\n",
    "    f.colorbar(im4, ax=subplot4)\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
